{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import shapelets as sha\n",
    "import importlib\n",
    "importlib.reload(sha)\n",
    "from operator import itemgetter\n",
    "random.seed(1)\n",
    "lcs=[]\n",
    "classes=[]\n",
    "xs=np.arange(0,30)\n",
    "def noisy(average_value):\n",
    "    return average_value+(math.cos(random.randint(0,360)*(math.pi/180))*0.1*average_value)\n",
    "no_per_class=50\n",
    "for i in range(no_per_class):\n",
    "    ys=[]\n",
    "    peak=np.random.choice(xs[1:-1])\n",
    "    for x in xs:\n",
    "        y=noisy(2)\n",
    "        ys.append(y)\n",
    "    ys[peak]=ys[peak-1]=ys[peak+1]=noisy(5)\n",
    "    lcs.append(np.stack((xs,ys)))\n",
    "    classes.append(\"alpha\")\n",
    "for i in range(no_per_class):\n",
    "    ys=[]\n",
    "    peak=np.random.choice(xs[:-1])\n",
    "    for x in xs:\n",
    "        y=noisy(2)\n",
    "        ys.append(y)\n",
    "    ys[peak]=noisy(10)\n",
    "    lcs.append(np.stack((xs,ys)))\n",
    "    classes.append(\"beta\")\n",
    "for i in range(no_per_class):\n",
    "    ys=[]\n",
    "    peak=np.random.choice(xs[:-3])\n",
    "    for x in xs:\n",
    "        y=noisy(2)\n",
    "        ys.append(y)\n",
    "    ys[peak]=noisy(10)\n",
    "    #if peak<xs[-2]:\n",
    "    ys[peak+2]=ys[peak+3]=noisy(5)\n",
    "    lcs.append(np.stack((xs,ys)))\n",
    "    classes.append(\"gamma\")\n",
    "for i in range(no_per_class):\n",
    "    ys=[]\n",
    "    #peak=np.random.choice(xs[:-3])\n",
    "    for x in xs:\n",
    "        y=noisy(2)\n",
    "        ys.append(y)\n",
    "    #ys[peak]=noisy(10)\n",
    "    #if peak<xs[-2]:\n",
    "    #ys[peak+2]=ys[peak+3]=noisy(5)\n",
    "    lcs.append(np.stack((xs,ys)))\n",
    "    classes.append(\"delta\")\n",
    "ids=[]\n",
    "for i in range(len(classes)):\n",
    "    ids.append(i)\n",
    "ob_state = {}\n",
    "for i, ob in enumerate(classes):\n",
    "    ob_state[i] = ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test, id_train, id_test = train_test_split(lcs, classes, ids, test_size=0.5, random_state=1, stratify=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sha)\n",
    "best_shapelets=[]\n",
    "time_res=1\n",
    "x=[]\n",
    "for n_donor, lc_donor in enumerate(x_train):\n",
    "    #Create lists with classifications of all time-series relative to the donor time series; one that the pool of shapelets is generated from\n",
    "    state_donor = y_train[n_donor]#y_train[n],x_train[n] and id_train[n] all refer to the attributes of the same time series\n",
    "    belong_class=[]\n",
    "    other_class=[]\n",
    "    for n, i in enumerate(id_train):\n",
    "        if y_train[n] == state_donor:\n",
    "            belong_class.append(i)\n",
    "        else:\n",
    "            other_class.append(i)\n",
    "    #calculate the entropy of the entire set, so it can be compared to the split set later\n",
    "    prop_belong = len(belong_class)/(len(belong_class)+len(other_class))\n",
    "    set_entropy = -(prop_belong)*math.log2(prop_belong)-(1-prop_belong)*math.log2(1-prop_belong)\n",
    "    pool=sha.generate_shapelets(lc_donor, 1, len(lc_donor[0]))#generate shapelets from the donor time-series, \n",
    "    #set the initial best value of information gain to 0 (improved by any split) and start testing the shapelets\n",
    "    best_gain=0\n",
    "    for shapelet in pool:\n",
    "        skip_shapelet=False#for entropy pruning\n",
    "        #set the order of distance calculations\n",
    "        #pick an other_class object first and then alternate between belong and other, when one group runs out, append the rest of the other group to the end\n",
    "        order=[]\n",
    "        if len(belong_class)<len(other_class):alternations=len(belong_class);larger_group=other_class\n",
    "        else: alternations=len(other_class); larger_group=belong_class\n",
    "        for i in range(alternations):\n",
    "            order.append(other_class[i])\n",
    "            order.append(belong_class[i])\n",
    "        for i in range(len(larger_group)-alternations):\n",
    "            order.append(larger_group[-(i+1)])\n",
    "        #start distance calculations\n",
    "        distances=[]\n",
    "        for n_lc in order:\n",
    "            if id_train[n_donor] == n_lc:\n",
    "                distance = 0\n",
    "            else:\n",
    "                lc=x_train[np.where(np.array(id_train)==n_lc)[0][0]]\n",
    "                distance=sha.distance_calculation(shapelet, lc, early_abandon=True)\n",
    "            #save the distance value together with the classification and lightcurve id\n",
    "            if n_lc in belong_class:\n",
    "                class_assign=1\n",
    "            else:\n",
    "                class_assign=0\n",
    "            distances.append((n_lc ,distance, class_assign))\n",
    "            #find the optimal split point if there are at least two distances calculated, then use entropy pruning to find if the shapelet still has a change to beat the best one found so far\n",
    "            if len(distances)>1:\n",
    "                best_split=sha.best_split_point(distances, set_entropy)\n",
    "                skip_shapelet=sha.entropy_pruning(best_gain, distances, best_split, len(belong_class), len(other_class), set_entropy)\n",
    "                #x.append((best_split, distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 0.5 0.75\n",
      "1.0 0.8112781244591328\n",
      "0.048794940695398525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "distances=[[-1,1,0],[-1,10,1],[-1,15,1],[-1,8,1],\n",
    "          [-1,11,0],[-1,10,0],[-1,3,1],[-1,7,1]]\n",
    "prop_belong=(above_belong+below_belong)/len(distances)\n",
    "split_point=10\n",
    "set_entropy = -(prop_belong)*math.log2(prop_belong)-(1-prop_belong)*math.log2(1-prop_belong)\n",
    "#split_point=sha.best_split_point(distances, set_entropy)\n",
    "above=[lc for lc in distances if lc[1]>=split_point]\n",
    "above_belong=sum([lc[2] for lc in above])\n",
    "below=[lc for lc in distances if lc[1]<split_point]\n",
    "below_belong=sum([lc[2] for lc in below])\n",
    "prop_above_belong=above_belong/len(above)\n",
    "prop_below_belong=below_belong/len(below)\n",
    "if prop_above_belong==1. or prop_above_belong==0.:\n",
    "    above_entropy=0\n",
    "else:\n",
    "    above_entropy = -(prop_above_belong)*math.log2(prop_above_belong)-(1-prop_above_belong)*math.log2(1-prop_above_belong)\n",
    "if prop_below_belong==1. or prop_below_belong==0.:\n",
    "    below_entropy =0\n",
    "else:\n",
    "    below_entropy = -(prop_below_belong)*math.log2(prop_below_belong)-(1-prop_below_belong)*math.log2(1-prop_below_belong)\n",
    "info_gain=set_entropy-(len(above)/(len(above)+len(below)))*(above_entropy)-(len(below)/(len(above)+len(below)))*(below_entropy)\n",
    "print(above_belong, below_belong, prop_above_belong, prop_below_belong)\n",
    "print(above_entropy,below_entropy)\n",
    "print(info_gain)\n",
    "best_gain=0.09235938389499487\n",
    "best_split=split_point\n",
    "belong_class_count=sum([lc[2] for lc in distances])\n",
    "other_class_count=len(distances)-belong_class_count\n",
    "\n",
    "\n",
    "calc_belong=sum([lc[2] for lc in distances])\n",
    "calc_other=len(distances)-calc_belong\n",
    "distances_bcs=deepcopy(distances) #best case scenario when all the distances are included\n",
    "distances_bcs.sort(key=itemgetter(1))\n",
    "maxdist=distances_bcs[-1][1]+1\n",
    "for add_belong in range(belong_class_count-calc_belong):\n",
    "    distances_bcs.append((-1,0,1))\n",
    "for add_other in range(other_class_count-calc_other):\n",
    "    distances_bcs.append((-1,maxdist,0))\n",
    "gain_bcs=sha.information_gain(distances_bcs, set_entropy, best_split)\n",
    "if isinstance(gain_bcs, str) == True:\n",
    "    ans= True\n",
    "else:\n",
    "    if gain_bcs<best_gain:\n",
    "        ans= True\n",
    "    else:\n",
    "        ans= False\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 0.5 0.6666666666666666\n",
      "1.0 0.9182958340544896\n",
      "0.015712127384097774\n"
     ]
    }
   ],
   "source": [
    "print(above_belong, below_belong, prop_above_belong, prop_below_belong)\n",
    "print(above_entropy,below_entropy)\n",
    "print(info_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8112781244591328"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 5, 'b': 5}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182925006850887"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_above_belong=0.33333\n",
    "-(prop_above_belong)*math.log2(prop_above_belong)-(1-prop_above_belong)*math.log2(1-prop_above_belong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 16\n",
      "[[-5, 1, 0], [-5, 1, 0], [-5, 1, 0], [-5, 1, 0], [-5, 2, 0], [-5, 7, 1], [-5, 7, 1], [-5, 10, 1], [-5, 11, 1], [-5, 15, 1], (-1, 0, 1), (-1, 0, 1), (-1, 0, 1), (-1, 0, 1), (-1, 0, 1), (-1, 16, 0), (-1, 16, 0), (-1, 16, 0), (-1, 16, 0), (-1, 16, 0)]\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances=[[-5,1,0],[-5,1,0],[-5,2,0],[-5,1,0],[-5,1,0],\n",
    "          [-5,11,1],[-5,10,1],[-5,15,1],[-5,7,1],[-5,7,1]]\n",
    "best_gain=0.04556599707503506\n",
    "best_split=4.5\n",
    "belong_class_count=10\n",
    "other_class_count=10\n",
    "set_entropy=1\n",
    "\n",
    "def entropy_pruning(best_gain, distances, best_split, belong_class_count, other_class_count, set_entropy):\n",
    "    calc_belong=sum([lc[2] for lc in distances])\n",
    "    calc_other=len(distances)-calc_belong\n",
    "    distances_bcs=deepcopy(distances) #best case scenario when all the distances are included\n",
    "    distances_bcs.sort(key=itemgetter(1))\n",
    "    maxdist=distances_bcs[-1][1]+1\n",
    "    print(calc_belong, calc_other, maxdist)\n",
    "    for add_belong in range(belong_class_count-calc_belong):\n",
    "        distances_bcs.append((-1,0,1))\n",
    "    for add_other in range(other_class_count-calc_other):\n",
    "        distances_bcs.append((-1,maxdist,0))\n",
    "    print(distances_bcs)\n",
    "    gain_bcs=sha.information_gain(distances_bcs, set_entropy, best_split)\n",
    "    print(gain_bcs)\n",
    "    if isinstance(gain_bcs, str) == True:\n",
    "        return True\n",
    "    else:\n",
    "        if gain_bcs<best_gain:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "entropy_pruning(best_gain, distances, best_split, belong_class_count, other_class_count, set_entropy)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
