{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import shapelets as sha\n",
    "import importlib\n",
    "importlib.reload(sha)\n",
    "from operator import itemgetter\n",
    "lcs=[]\n",
    "classes=[]\n",
    "xs=np.arange(0,30)\n",
    "def noisy(average_value):\n",
    "    return average_value+(math.cos(random.randint(0,360)*(math.pi/180))*0.01*average_value)\n",
    "no_per_class=10\n",
    "for i in range(no_per_class):\n",
    "    ys=[]\n",
    "    peak=np.random.choice(xs[1:-1])\n",
    "    for x in xs:\n",
    "        y=noisy(2)\n",
    "        ys.append(y)\n",
    "    ys[peak]=ys[peak-1]=ys[peak+1]=noisy(5)\n",
    "    lcs.append(np.stack((xs,ys)))\n",
    "    classes.append(\"alpha\")\n",
    "for i in range(no_per_class):\n",
    "    ys=[]\n",
    "    peak=np.random.choice(xs[:-1])\n",
    "    for x in xs:\n",
    "        y=noisy(2)\n",
    "        ys.append(y)\n",
    "    ys[peak]=noisy(10)\n",
    "    lcs.append(np.stack((xs,ys)))\n",
    "    classes.append(\"beta\")\n",
    "for i in range(no_per_class):\n",
    "    ys=[]\n",
    "    peak=np.random.choice(xs[:-3])\n",
    "    for x in xs:\n",
    "        y=noisy(2)\n",
    "        ys.append(y)\n",
    "    ys[peak]=noisy(10)\n",
    "    #if peak<xs[-2]:\n",
    "    ys[peak+2]=ys[peak+3]=noisy(5)\n",
    "    lcs.append(np.stack((xs,ys)))\n",
    "    classes.append(\"gamma\")\n",
    "for i in range(20):\n",
    "    ys=[]\n",
    "    #peak=np.random.choice(xs[:-3])\n",
    "    for x in xs:\n",
    "        y=noisy(2)\n",
    "        ys.append(y)\n",
    "    #ys[peak]=noisy(10)\n",
    "    #if peak<xs[-2]:\n",
    "    #ys[peak+2]=ys[peak+3]=noisy(5)\n",
    "    lcs.append(np.stack((xs,ys)))\n",
    "    classes.append(\"delta\")\n",
    "ids=[]\n",
    "for i in range(len(classes)):\n",
    "    ids.append(i)\n",
    "ob_state = {}\n",
    "for i, ob in enumerate(classes):\n",
    "    ob_state[i] = ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([5.0409576, 5.0409576, 5.0409576]), 0.7219280948873623, 'alpha'),\n",
       " (array([10.0052336 ,  2.01989044,  1.99030381]), 0.7219280948873623, 'beta'),\n",
       " (array([10.0052336 ,  1.98714425,  5.02424048]), 0.7219280948873623, 'gamma'),\n",
       " (array([2.0184101 , 2.00551275, 2.00845237, 1.99348864, 1.98381966,\n",
       "         1.98661739, 2.01338261, 1.99      , 2.00034905, 2.00551275,\n",
       "         2.00781462, 2.01576022, 1.98381966, 1.99030381, 1.98002741,\n",
       "         2.00749213, 2.00104672, 1.99482362, 2.00139513, 1.99092019,\n",
       "         2.00034905, 1.98361696, 1.98002741, 1.99123258, 2.01      ,\n",
       "         1.98285665, 1.98172909]), 0.9709505944546686, 'delta')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tested_classes=[]\n",
    "best_shapelets=[]\n",
    "time_res=1\n",
    "for n_donor, lc_donor in enumerate(lcs):\n",
    "    #Create lists with classifications of all time-series relative to the donor time series; one that the pool of shapelets is generated from\n",
    "    state_donor = ob_state[ids[n_donor]]\n",
    "    if state_donor not in tested_classes:\n",
    "        tested_classes.append(state_donor)\n",
    "    else:\n",
    "        continue\n",
    "    belong_class=[]\n",
    "    other_class=[]\n",
    "    for n_lc in range(len(lcs)):\n",
    "        if ob_state[ids[n_lc]] == state_donor:\n",
    "            belong_class.append(n_lc)\n",
    "        else:\n",
    "            other_class.append(n_lc)\n",
    "    #calculate the entropy of the entire set, so it can be compared to the split set later\n",
    "    prop_belong = len(belong_class)/(len(belong_class)+len(other_class))\n",
    "    set_entropy = -(prop_belong)*math.log2(prop_belong)-(1-prop_belong)*math.log2(1-prop_belong)\n",
    "    pool=sha.generate_shapelets(lc_donor, 1, len(lc_donor[0]))#generate shapelets from the donor time-series, \n",
    "    best_gain=0#set the initial best value of information gain to 0 (improved by any split) \n",
    "    for shapelet in pool:\n",
    "        skip_shapelet=False#for entropy pruning\n",
    "        #set the order of distance calculations\n",
    "        #pick an other_class object first and then alternate between belong and other, when one group runs out, append the rest of the other group to the end\n",
    "        order=[]\n",
    "        if len(belong_class)<len(other_class):alternations=len(belong_class);larger_group=other_class\n",
    "        else: alternations=len(other_class); larger_group=belong_class\n",
    "        for i in range(alternations):\n",
    "            order.append(other_class[i])\n",
    "            order.append(belong_class[i])\n",
    "        for i in range(len(larger_group)-alternations):\n",
    "            order.append(larger_group[-(i+1)])\n",
    "        #start distance calculations\n",
    "        distances=[]\n",
    "        for n_lc in order:\n",
    "            lc=lcs[n_lc]\n",
    "            distance=sha.distance_calculation(n_lc, lc, shapelet, time_res, belong_class)\n",
    "           # print(n_donor, distance, shapelet)\n",
    "            distances.append(distance)\n",
    "            if len(distances)>1:\n",
    "                best_split=sha.best_split_point(distances, set_entropy)\n",
    "                skip_shapelet=sha.entropy_pruning(best_gain, distances, best_split, len(belong_class), len(other_class), set_entropy)\n",
    "                if skip_shapelet==True:\n",
    "                    break\n",
    "        if skip_shapelet==False:\n",
    "            gain=sha.information_gain(distances, set_entropy, best_split)\n",
    "            #print(shapelet)\n",
    "            #print(distances)\n",
    "            if gain>best_gain:\n",
    "                best_gain=gain\n",
    "                best_shapelet=shapelet\n",
    "    best_shapelets.append((best_shapelet, best_gain, state_donor))\n",
    "best_shapelets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
